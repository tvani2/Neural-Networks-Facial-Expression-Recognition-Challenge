{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvani2/Neural-Networks-Facial-Expression-Recognition-Challenge/blob/main/Expr_recognition_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA4OOlsqpJ7A"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle wandb onnx -Uq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9RmKCeMHHVX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6wFpzqVHJl0"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/cs231n/assignments/assignment4/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KNpcM-yHVtP"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ4VjiZrPEAz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "# Change the file path to the correct location after unzipping\n",
        "df = pd.read_csv('./train.csv')\n",
        "X = df['pixels']\n",
        "y = df['emotion']\n",
        "\n",
        "train_size = 0.70\n",
        "val_size = 0.15\n",
        "test_size = 0.15\n",
        "X_temp, X_test_new, y_temp, y_test_new = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=42, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=(val_size / (train_size + val_size)), random_state=42, stratify=y_temp\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIJwMOE3QbpT"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "def fast_process_pixels(pixel_series):\n",
        "    pixel_lists = pixel_series.str.split()\n",
        "    pixel_array = np.array(pixel_lists.tolist(), dtype=np.float32)\n",
        "    return pixel_array.reshape(-1, 48, 48, 1) / 255.0\n",
        "\n",
        "X_train_normalized = fast_process_pixels(X_train)\n",
        "X_val_normalized = fast_process_pixels(X_val)\n",
        "X_test_new_normalized = fast_process_pixels(X_test_new)\n",
        "\n",
        "print(\"Data preprocessing completed!\")\n",
        "print(f\"Train shape: {X_train_normalized.shape}\")\n",
        "print(f\"Val shape: {X_val_normalized.shape}\")\n",
        "print(f\"Test shape: {X_test_new_normalized.shape}\")\n",
        "\n",
        "# === 4. Dataset Class ===\n",
        "class FastEmotionDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = torch.from_numpy(images).permute(0, 3, 1, 2).float()\n",
        "        self.labels = torch.from_numpy(labels.values).long()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wr-paQBJQn-I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
        "\n",
        "# === 5. Transforms ===\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# === 6. Create Datasets ===\n",
        "train_dataset = FastEmotionDataset(X_train_normalized, y_train, transform=train_transforms)\n",
        "val_dataset = FastEmotionDataset(X_val_normalized, y_val, transform=val_test_transforms)\n",
        "test_dataset = FastEmotionDataset(X_test_new_normalized, y_test_new, transform=val_test_transforms)\n",
        "\n",
        "# === 7. Compute Class Weights and Sampler ===\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
        "sample_weights = np.array([class_weights_dict[label] for label in y_train])\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# === 8. DataLoaders ===\n",
        "batch_size = 64\n",
        "num_workers = 0\n",
        "pin_memory = torch.cuda.is_available()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler,\n",
        "                          num_workers=num_workers, pin_memory=pin_memory,\n",
        "                          persistent_workers=num_workers > 0)\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        num_workers=num_workers, pin_memory=pin_memory,\n",
        "                        persistent_workers=num_workers > 0)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
        "                         num_workers=num_workers, pin_memory=pin_memory,\n",
        "                         persistent_workers=num_workers > 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoxISxe_QpG5"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, min_delta=0.001, restore_best_weights=True):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.best_loss = float('inf')\n",
        "        self.counter = 0\n",
        "        self.best_weights = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            if self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.counter += 1\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            if self.restore_best_weights and self.best_weights:\n",
        "                model.load_state_dict(self.best_weights)\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "gc.collect()\n",
        "print(\"Pipeline is ready for model training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJIrasvLKddx"
      },
      "outputs": [],
      "source": [
        "class EmotionDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        # Convert to torch tensors and rearrange dimensions (H, W, C) -> (C, H, W)\n",
        "        self.images = torch.FloatTensor(images).permute(0, 3, 1, 2)\n",
        "        self.labels = torch.LongTensor(labels.values)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Define data augmentation transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# No augmentation for validation and test\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Same normalization as training\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = EmotionDataset(X_train_normalized, y_train, transform=train_transforms)\n",
        "val_dataset = EmotionDataset(X_val_normalized, y_val, transform=val_test_transforms)\n",
        "test_dataset = EmotionDataset(X_test_new_normalized, y_test_new, transform=val_test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lADlunQlQ7E_"
      },
      "outputs": [],
      "source": [
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Create sample weights for each training sample\n",
        "sample_weights = [class_weights_dict[label] for label in y_train]\n",
        "sampler = WeightedRandomSampler(\n",
        "    weights=sample_weights,\n",
        "    num_samples=len(sample_weights),\n",
        "    replacement=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA2u5PJlQ8Ah"
      },
      "outputs": [],
      "source": [
        "# Create DataLoaders\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_new_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Print class distribution info\n",
        "print(\"Class distribution in training set:\")\n",
        "print(y_train.value_counts().sort_index())\n",
        "print(f\"\\nClass weights: {class_weights_dict}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCvzoTeSD4EV"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"Facial_Expression_Recognition_1\", name=\"EmotionCNN_Run1\")\n",
        "\n",
        "wandb.config.update({\n",
        "    \"architecture\": \"EmotionCNN\",\n",
        "    \"dropout_feature\": 0.25,\n",
        "    \"dropout_classifier\": 0.5,\n",
        "    \"scheduler\": \"ReduceLROnPlateau\",\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"scheduler_patience\": 7,\n",
        "    \"gradient_clip_norm\": 1.0,\n",
        "    \"early_stopping_patience\": 7,\n",
        "    \"input_size\": (48, 48),\n",
        "    \"num_classes\": 7,\n",
        "    \"batch_norm\": True,\n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 20,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"weight_decay\" : 1e-5,\n",
        "})\n",
        "\n",
        "raw_data_artifact = wandb.Artifact(\n",
        "    name=\"facial-expression-dataset\",\n",
        "    type=\"dataset\",\n",
        "    description=\"Facial Expression Recognition Challenge Dataset\"\n",
        ")\n",
        "# Log the artifact to the current run\n",
        "wandb.log_artifact(raw_data_artifact)\n",
        "\n",
        "print(\"Data loaded and logged as a wandb artifact.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4_cPob-HA_C"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EmotionCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(EmotionCNN, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),  # (1, 48, 48) -> (64, 48, 48)\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),  # -> (64, 24, 24)\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # -> (128, 24, 24)\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),  # -> (128, 12, 12)\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),  # -> (256, 12, 12)\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),  # -> (256, 6, 6)\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),  # -> (256*6*6)\n",
        "            nn.Linear(256 * 6 * 6, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqPb05z10doE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Dataset, WeightedRandomSampler # Ensure these are imported\n",
        "from torchvision import transforms # Ensure transforms is imported\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = EmotionCNN(num_classes=7).to(device)\n",
        "wandb.watch(model, log=\"all\")\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "# Track loss and accuracy\n",
        "train_losses, train_accuracies = [], []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Add scheduler and early stopping\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.1, verbose=True)\n",
        "early_stopping = EarlyStopping(patience=7, min_delta=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    # Use the pre-defined train_loader\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_accuracy = 100. * correct_train / total_train\n",
        "    train_losses.append(avg_train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    all_val_preds, all_val_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Use the pre-defined val_loader\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "\n",
        "            running_val_loss += val_loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += predicted.eq(labels).sum().item()\n",
        "            all_val_preds.extend(predicted.cpu().numpy())\n",
        "            all_val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = running_val_loss / len(val_loader.dataset)\n",
        "    val_accuracy = 100. * correct_val / total_val\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d}: Train Loss = {avg_train_loss:.4f}, Train Acc = {train_accuracy:.2f}%, \"\n",
        "          f\"Val Loss = {avg_val_loss:.4f}, Val Acc = {val_accuracy:.2f}%\")\n",
        "\n",
        "    # Log metrics to wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": avg_train_loss,\n",
        "        \"train_accuracy\": train_accuracy,\n",
        "        \"val_loss\": avg_val_loss,\n",
        "        \"val_accuracy\": val_accuracy,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "    })\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    # Check for early stopping\n",
        "    if early_stopping(avg_val_loss, model):\n",
        "        print(f\"Early stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "# Evaluate on test set (using the pre-defined test_loader)\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_accuracy = accuracy_score(all_labels, all_preds) * 100\n",
        "print(f\"\\n✅ Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Log final test accuracy to wandb\n",
        "wandb.log({\"test_accuracy\": test_accuracy})\n",
        "\n",
        "# Finish the wandb run\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Na2krx9aWjhb"
      },
      "outputs": [],
      "source": [
        "# Define EmotionCNN\n",
        "class EmotionCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(EmotionCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 6 * 6, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"Facial_Expression_Recognition_1\", name=\"EmotionCNN_Run1\")\n",
        "\n",
        "wandb.config.update({\n",
        "    \"architecture\": \"EmotionCNN\",\n",
        "    \"dropout_feature\": 0.25,\n",
        "    \"dropout_classifier\": 0.5,\n",
        "    \"scheduler\": \"ReduceLROnPlateau\",\n",
        "    \"optimizer\": \"Adam\",\n",
        "    \"scheduler_patience\": 5,\n",
        "    \"gradient_clip_norm\": 1.0,\n",
        "    \"early_stopping_patience\": 10,\n",
        "    \"input_size\": (48, 48),\n",
        "    \"num_classes\": 7,\n",
        "    \"batch_norm\": True,\n",
        "    \"batch_size\": 64,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 0.0005,\n",
        "    \"weight_decay\": 1e-5,\n",
        "})\n",
        "\n",
        "# Create a wandb artifact for the dataset\n",
        "raw_data_artifact = wandb.Artifact(\n",
        "    name=\"facial-expression-dataset\",\n",
        "    type=\"dataset\",\n",
        "    description=\"Facial Expression Recognition Challenge Dataset\"\n",
        ")\n",
        "# Log the artifact to the current run\n",
        "wandb.log_artifact(raw_data_artifact)\n",
        "\n",
        "print(\"Data loaded and logged as a wandb artifact.\")"
      ],
      "metadata": {
        "id": "IHk4hwwhbjuq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb24df09-7ce9-4b17-fb36-5f4d20961f10"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">EmotionCNN_Run1</strong> at: <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/kgj4ftmx' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/kgj4ftmx</a><br> View project at: <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250601_170931-kgj4ftmx/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250601_172629-liby3ffx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/liby3ffx' target=\"_blank\">EmotionCNN_Run1</a></strong> to <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/liby3ffx' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/liby3ffx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and logged as a wandb artifact.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, min_delta=0.001, restore_best_weights=True):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.best_loss = float('inf')\n",
        "        self.counter = 0\n",
        "        self.best_weights = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "            if self.restore_best_weights:\n",
        "                self.best_weights = model.state_dict().copy()\n",
        "        else:\n",
        "            self.counter += 1\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            if self.restore_best_weights and self.best_weights:\n",
        "                model.load_state_dict(self.best_weights)\n",
        "            return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "1ybqMO2Qf5ID"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader # Ensure DataLoader is imported\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data import Dataset, WeightedRandomSampler # Ensure these are imported\n",
        "from torchvision import transforms # Ensure transforms is imported\n",
        "from sklearn.utils.class_weight import compute_class_weight # Ensure this is imported\n",
        "import gc # Ensure gc is imported for garbage collection\n",
        "\n",
        "try:\n",
        "    class_weights = compute_class_weight(\n",
        "        'balanced',\n",
        "        classes=np.unique(y_train),\n",
        "        y=y_train\n",
        "    )\n",
        "    class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "    sample_weights = [class_weights_dict[label] for label in y_train]\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=sample_weights,\n",
        "        num_samples=len(sample_weights),\n",
        "        replacement=True\n",
        "    )\n",
        "\n",
        "    # Create DataLoaders\n",
        "    batch_size = 64\n",
        "    num_workers = 0\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=num_workers)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    # Print class distribution info\n",
        "    print(\"Class distribution in training set:\")\n",
        "    print(y_train.value_counts().sort_index())\n",
        "    print(f\"\\nClass weights: {class_weights_dict}\")\n",
        "except NameError:\n",
        "    print(\"Error: y_train, train_dataset, val_dataset, or test_dataset not defined. Please load your data.\")\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize model\n",
        "model = EmotionCNN(num_classes=7).to(device)\n",
        "wandb.watch(model, log=\"all\")  # Track model gradients and parameters\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
        "\n",
        "# Track metrics\n",
        "train_losses, train_accuracies = [], []\n",
        "val_losses, val_accuracies = [], []\n",
        "\n",
        "# Scheduler and early stopping\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5, verbose=True)\n",
        "early_stopping = EarlyStopping(patience=10, min_delta=0.0005)\n",
        "\n",
        "# Save best model\n",
        "best_val_loss = float('inf')\n",
        "model_save_path = \"best_model.pth\"\n",
        "\n",
        "epochs = 29\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += predicted.eq(labels).sum().item()\n",
        "\n",
        "    avg_train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_accuracy = 100. * correct_train / total_train\n",
        "    train_losses.append(avg_train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    running_val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    all_val_preds, all_val_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "\n",
        "            running_val_loss += val_loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += predicted.eq(labels).sum().item()\n",
        "            all_val_preds.extend(predicted.cpu().numpy())\n",
        "            all_val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = running_val_loss / len(val_loader.dataset)\n",
        "    val_accuracy = 100. * correct_val / total_val\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    # Log training and validation metrics to wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": avg_train_loss,\n",
        "        \"train_accuracy\": train_accuracy,\n",
        "        \"val_loss\": avg_val_loss,\n",
        "        \"val_accuracy\": val_accuracy,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "    })\n",
        "\n",
        "    print(f\"Epoch {epoch+1:02d}: Train Loss = {avg_train_loss:.4f}, Train Acc = {train_accuracy:.2f}%, \"\n",
        "          f\"Val Loss = {avg_val_loss:.4f}, Val Acc = {val_accuracy:.2f}%\")\n",
        "\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "        # Log the best model as a wandb artifact\n",
        "        model_artifact = wandb.Artifact(\n",
        "            name=f\"best-model-epoch-{epoch+1}\",\n",
        "            type=\"model\",\n",
        "            description=\"Best EmotionCNN model based on validation loss\"\n",
        "        )\n",
        "        model_artifact.add_file(model_save_path)\n",
        "        wandb.log_artifact(model_artifact)\n",
        "\n",
        "    if early_stopping(avg_val_loss, model):\n",
        "        print(f\"Early stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "# Load best model before final test\n",
        "model.load_state_dict(torch.load(model_save_path))\n",
        "\n",
        "# Final Evaluation\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_accuracy = accuracy_score(all_labels, all_preds) * 100\n",
        "print(f\"\\n✅ Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Log test accuracy to wandb\n",
        "wandb.log({\"test_accuracy\": test_accuracy})\n",
        "\n",
        "# Finish the wandb run\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlYhX3pmnaXI",
        "outputId": "4dcc25fa-93ed-48c2-dfb2-405dd95529a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution in training set:\n",
            "emotion\n",
            "0    2797\n",
            "1     306\n",
            "2    2867\n",
            "3    5051\n",
            "4    3380\n",
            "5    2219\n",
            "6    3475\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class weights: {0: np.float64(1.0263547678635272), 1: np.float64(9.381419234360411), 2: np.float64(1.0012955304200508), 3: np.float64(0.568345730689821), 4: np.float64(0.849323753169907), 5: np.float64(1.2936972896414085), 6: np.float64(0.8261048304213772)}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: Train Loss = 1.9714, Train Acc = 17.06%, Val Loss = 1.8675, Val Acc = 21.50%\n",
            "Epoch 02: Train Loss = 1.8906, Train Acc = 20.22%, Val Loss = 1.8286, Val Acc = 22.57%\n",
            "Epoch 03: Train Loss = 1.8584, Train Acc = 22.36%, Val Loss = 1.7610, Val Acc = 33.36%\n",
            "Epoch 04: Train Loss = 1.8251, Train Acc = 23.71%, Val Loss = 1.9802, Val Acc = 25.89%\n",
            "Epoch 05: Train Loss = 1.7988, Train Acc = 25.83%, Val Loss = 1.7045, Val Acc = 34.87%\n",
            "Epoch 06: Train Loss = 1.7696, Train Acc = 27.13%, Val Loss = 1.7095, Val Acc = 29.79%\n",
            "Epoch 07: Train Loss = 1.7575, Train Acc = 28.18%, Val Loss = 1.6222, Val Acc = 37.15%\n",
            "Epoch 08: Train Loss = 1.7438, Train Acc = 28.68%, Val Loss = 1.6289, Val Acc = 38.01%\n",
            "Epoch 09: Train Loss = 1.7332, Train Acc = 29.25%, Val Loss = 1.6128, Val Acc = 37.80%\n",
            "Epoch 10: Train Loss = 1.7171, Train Acc = 29.88%, Val Loss = 1.6035, Val Acc = 41.54%\n",
            "Epoch 11: Train Loss = 1.7119, Train Acc = 30.54%, Val Loss = 1.5664, Val Acc = 41.98%\n",
            "Epoch 12: Train Loss = 1.7066, Train Acc = 31.18%, Val Loss = 1.5816, Val Acc = 41.54%\n",
            "Epoch 13: Train Loss = 1.6901, Train Acc = 32.23%, Val Loss = 1.5381, Val Acc = 42.21%\n",
            "Epoch 14: Train Loss = 1.6920, Train Acc = 31.55%, Val Loss = 1.5336, Val Acc = 43.46%\n",
            "Epoch 15: Train Loss = 1.6798, Train Acc = 32.42%, Val Loss = 1.5541, Val Acc = 41.03%\n",
            "Epoch 16: Train Loss = 1.6742, Train Acc = 32.79%, Val Loss = 1.5169, Val Acc = 44.14%\n",
            "Epoch 17: Train Loss = 1.6663, Train Acc = 33.58%, Val Loss = 1.5394, Val Acc = 42.98%\n",
            "Epoch 18: Train Loss = 1.6535, Train Acc = 33.10%, Val Loss = 1.4770, Val Acc = 41.40%\n",
            "Epoch 19: Train Loss = 1.6484, Train Acc = 33.62%, Val Loss = 1.5399, Val Acc = 40.14%\n",
            "Epoch 20: Train Loss = 1.6554, Train Acc = 33.60%, Val Loss = 1.5188, Val Acc = 39.28%\n",
            "Epoch 21: Train Loss = 1.6353, Train Acc = 35.42%, Val Loss = 1.4357, Val Acc = 44.79%\n",
            "Epoch 22: Train Loss = 1.6109, Train Acc = 36.81%, Val Loss = 1.4901, Val Acc = 43.07%\n",
            "Epoch 23: Train Loss = 1.5908, Train Acc = 37.63%, Val Loss = 1.4473, Val Acc = 45.46%\n",
            "Epoch 24: Train Loss = 1.5818, Train Acc = 37.56%, Val Loss = 1.5083, Val Acc = 42.26%\n",
            "Epoch 25: Train Loss = 1.5774, Train Acc = 37.89%, Val Loss = 1.4742, Val Acc = 43.65%\n",
            "Epoch 26: Train Loss = 1.5729, Train Acc = 37.98%, Val Loss = 1.4499, Val Acc = 44.53%\n",
            "Epoch 27: Train Loss = 1.5581, Train Acc = 38.83%, Val Loss = 1.3939, Val Acc = 47.06%\n",
            "Epoch 28: Train Loss = 1.5448, Train Acc = 39.21%, Val Loss = 1.3898, Val Acc = 47.57%\n",
            "Epoch 29: Train Loss = 1.5495, Train Acc = 39.84%, Val Loss = 1.4191, Val Acc = 44.95%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyONJv6AXLxYFumxMVGObulY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}