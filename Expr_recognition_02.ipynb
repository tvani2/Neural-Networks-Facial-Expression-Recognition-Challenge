{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNedQzeAkAO5utzbz4rYYB5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvani2/Neural-Networks-Facial-Expression-Recognition-Challenge/blob/main/Expr_recognition_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBRs595DApib",
        "outputId": "693a34e7-47ba-4c5f-faf5-8c403f82c52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install kaggle wandb onnx -Uq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0gsWlq3A2Jv",
        "outputId": "76c42c2f-cff6-4f76-dfd0-e19deb6e2ef4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "ru1wQJVPA4u2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/cs231n/assignments/assignment4/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "ucyKzBLvA7vW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "-RnUxttpA8g3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-Ts6C_oA_cw",
        "outputId": "f2190550-acca-4e60-af7d-fdb7875e5130"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading challenges-in-representation-learning-facial-expression-recognition-challenge.zip to /content\n",
            " 88% 250M/285M [00:00<00:00, 816MB/s] \n",
            "100% 285M/285M [00:04<00:00, 68.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip challenges-in-representation-learning-facial-expression-recognition-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIpUE7L5BCPF",
        "outputId": "8b1631cf-a181-4993-99c6-67596a37387f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  challenges-in-representation-learning-facial-expression-recognition-challenge.zip\n",
            "  inflating: example_submission.csv  \n",
            "  inflating: fer2013.tar.gz          \n",
            "  inflating: icml_face_data.csv      \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "8E6ZYN9DCTUD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f70ea21c-16c1-4a9b-edae-78d3685df111"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"Facial_Expression_Recognition_1\",\n",
        "    config={\n",
        "        \"architecture\": \"ImprovedCNN_Combined\",\n",
        "        \"num_classes\": 7,\n",
        "        \"dropout_prob\": 0.3,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"scheduler\": \"ReduceLROnPlateau\",\n",
        "        \"scheduler_patience\": 5,\n",
        "        \"scheduler_factor\": 0.1,\n",
        "        \"loss_function\": \"CrossEntropyLoss\",\n",
        "        \"batch_size\": 64,\n",
        "        \"epochs\": 20,\n",
        "        \"input_size\": (48, 48)\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "eyJAwn8hCWRx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "91e1bd40-d37a-48a9-cc78-b1a9e0d8f151"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">prime-river-2</strong> at: <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_CNN/runs/6b842f1d' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_CNN/runs/6b842f1d</a><br> View project at: <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_CNN' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_CNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250531_130507-6b842f1d/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250531_140448-dvb3omyf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/dvb3omyf' target=\"_blank\">neat-snowflake-3</a></strong> to <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/dvb3omyf' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/dvb3omyf</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import os\n",
        "import pandas as pd\n",
        "# Create a wandb artifact\n",
        "# Reference [1] explains how to create an artifact with a type and project\n",
        "raw_data_artifact = wandb.Artifact(\n",
        "    name=\"facial-expression-dataset\",\n",
        "    type=\"dataset\",\n",
        "    description=\"Facial Expression Recognition Challenge Dataset\"\n",
        ")\n",
        "# Log the artifact to the current run\n",
        "wandb.log_artifact(raw_data_artifact)\n",
        "\n",
        "print(\"Data loaded and logged as a wandb artifact.\")"
      ],
      "metadata": {
        "id": "ht-h6GSeCa_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e62796c6-8758-4c79-d7ef-cb6927df1513"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded and logged as a wandb artifact.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # Main PyTorch Library\n",
        "from torch import nn # Used for creating the layers and loss function\n",
        "from torch.optim import Adam # Adam Optimizer\n",
        "import torchvision.transforms as transforms # Transform function used to modify and preprocess all the images\n",
        "from torch.utils.data import Dataset, DataLoader # Dataset class and DataLoader for creating the objects\n",
        "from sklearn.preprocessing import LabelEncoder # Label Encoder to encode the classes from strings to numbers\n",
        "import matplotlib.pyplot as plt # Used for visualizing the images and plotting the training progress\n",
        "from PIL import Image # Used to read the images from the directory\n",
        "import pandas as pd # Used to read/create dataframes (csv) and process tabular data\n",
        "import numpy as np # preprocessing and numerical/mathematical operations\n",
        "import os # Used to read the images path from the directory\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # detect the GPU if any, if not use CPU, change cuda to mps if you have a mac\n",
        "print(\"Device available: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DJldhFyBD0Q",
        "outputId": "d52c3973-b228-414d-feee-f6109080b842"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device available:  cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "# Change the file path to the correct location after unzipping\n",
        "df = pd.read_csv('./train.csv')\n",
        "X = df['pixels']\n",
        "y = df['emotion']\n",
        "\n",
        "train_size = 0.70\n",
        "val_size = 0.15\n",
        "test_size = 0.15\n",
        "X_temp, X_test_new, y_temp, y_test_new = train_test_split(\n",
        "    X, y, test_size=test_size, random_state=42, stratify=y\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=(val_size / (train_size + val_size)), random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# --- Convert pandas Series of string pixels to numerical NumPy array ---\n",
        "# Function to convert a space-separated string of pixels into a NumPy array and reshape\n",
        "def process_pixels_string(pixel_string):\n",
        "    return np.array(pixel_string.split(), dtype=np.uint8).reshape(48, 48)\n",
        "\n",
        "# Apply the function to each element in the Series and stack them\n",
        "# This will create a 3D numpy array where each element is a 48x48 image\n",
        "X_train_np = np.stack(X_train.apply(process_pixels_string).values)\n",
        "X_val_np = np.stack(X_val.apply(process_pixels_string).values)\n",
        "X_test_new_np = np.stack(X_test_new.apply(process_pixels_string).values)\n",
        "\n",
        "# Expand dimensions to add a channel dimension (for grayscale images)\n",
        "X_train_np = np.expand_dims(X_train_np, axis=-1)\n",
        "X_val_np = np.expand_dims(X_val_np, axis=-1)\n",
        "X_test_new_np = np.expand_dims(X_test_new_np, axis=-1)\n",
        "\n",
        "# --- Normalization Function ---\n",
        "def normalize_pixels(image_array):\n",
        "    \"\"\"\n",
        "    Scales pixel values from [0, 255] to [0, 1].\n",
        "\n",
        "    Args:\n",
        "        image_array (numpy.ndarray): Input image data (can be 2D or 3D/4D array).\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Normalized image data.\n",
        "    \"\"\"\n",
        "    # Ensure the data type is float before division\n",
        "    # Dividing uint8 by an integer might perform integer division.\n",
        "    # Dividing uint8 by a float results in float.\n",
        "    return image_array / 255.0\n",
        "\n",
        "# --- Apply Normalization ---\n",
        "X_train_normalized = normalize_pixels(X_train_np)\n",
        "X_val_normalized = normalize_pixels(X_val_np)\n",
        "X_test_new_normalized = normalize_pixels(X_test_new_np)"
      ],
      "metadata": {
        "id": "RqU01OMtDMcR"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Convert Normalized NumPy Arrays and Labels to Tensors ---\n",
        "\n",
        "def convert_to_tensors(image_arrays, labels):\n",
        "\n",
        "    image_tensors = torch.tensor(image_arrays, dtype=torch.float32).permute(0, 3, 1, 2)\n",
        "\n",
        "    # Convert labels (which might be a pandas Series) to a NumPy array first, then to long tensor.\n",
        "    # torch.long is used for classification labels in CrossEntropyLoss.\n",
        "    if isinstance(labels, pd.Series):\n",
        "        label_tensors = torch.tensor(labels.values, dtype=torch.long)\n",
        "    else: # Assuming it's already a numpy array\n",
        "         label_tensors = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "\n",
        "    return image_tensors, label_tensors\n",
        "\n",
        "# --- Apply Conversion to your Data Splits ---\n",
        "\n",
        "X_train_tensor, y_train_tensor = convert_to_tensors(X_train_normalized, y_train)\n",
        "X_val_tensor, y_val_tensor = convert_to_tensors(X_val_normalized, y_val)\n",
        "X_test_new_tensor, y_test_new_tensor = convert_to_tensors(X_test_new_normalized, y_test_new)\n"
      ],
      "metadata": {
        "id": "tPvyo49IFGnE"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- Create Custom Dataset Class ---\n",
        "\n",
        "class EmotionDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for facial emotion data.\"\"\"\n",
        "\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            images (torch.Tensor): Tensor of images (N, C, H, W).\n",
        "            labels (torch.Tensor): Tensor of labels (N,).\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels) # The number of samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get image and label for the given index\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        # Apply transform if any (though we've already normalized,\n",
        "        # this is where augmentation would typically go for train)\n",
        "        if self.transform:\n",
        "             pass\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- Create Datasets ---\n",
        "train_dataset = EmotionDataset(X_train_tensor, y_train_tensor, transform=None)\n",
        "val_dataset = EmotionDataset(X_val_tensor, y_val_tensor, transform=None)\n",
        "test_new_dataset = EmotionDataset(X_test_new_tensor, y_test_new_tensor, transform=None)"
      ],
      "metadata": {
        "id": "ZUh8qupfFS1s"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64 # A common starting batch size\n",
        "\n",
        "# Create DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# val_dataloader: shuffle=False - order doesn't matter for evaluation\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# test_new_dataloader: shuffle=False - order doesn't matter for final evaluation\n",
        "test_new_dataloader = DataLoader(test_new_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "o6upPge8F9Bf"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImprovedCNN_Combined(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=7, dropout_prob=0.3):\n",
        "        super(ImprovedCNN_Combined, self).__init__()\n",
        "\n",
        "        # Block 1: Conv -> BatchNorm -> ReLU -> Pool\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # Output: 32x24x24\n",
        "\n",
        "        # Block 2: Conv -> BatchNorm -> ReLU -> Pool\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # Output: 64x12x12\n",
        "\n",
        "        # Block 3: Conv -> BatchNorm -> ReLU -> Pool\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # Output: 128x6x6\n",
        "\n",
        "        # Flattened size: 128 * 6 * 6 = 4608\n",
        "        # Fully connected layers with Dropout\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 512) # Added an intermediate linear layer\n",
        "        self.dropout1 = nn.Dropout(dropout_prob)\n",
        "\n",
        "        self.fc2 = nn.Linear(512, num_classes) # Final classification layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x)))) # -> N x 32 x 24 x 24\n",
        "\n",
        "        # Block 2\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x)))) # -> N x 64 x 12 x 12\n",
        "\n",
        "        # Block 3\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x)))) # -> N x 128 x 6 x 6\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(-1, 128 * 6 * 6) # -> N x 4608\n",
        "\n",
        "        # Fully connected layers with ReLU and Dropout\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x) # Output layer (no activation, CrossEntropyLoss handles Softmax)\n",
        "        return x"
      ],
      "metadata": {
        "id": "u_C07UMXF_Lz"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 7\n",
        "model = ImprovedCNN_Combined(num_classes=num_classes, dropout_prob=0.3)\n",
        "\n",
        "model.to(device)\n",
        "print(f\"Model moved to: {device}\")\n",
        "wandb.watch(model, log=\"all\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5uRnNXPIO-m",
        "outputId": "60cbb3bc-1556-4c85-b048-dbdee4c8b22d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model moved to: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import wandb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Learning rate and optimizer\n",
        "learning_rate = 0.001\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.1,\n",
        "    patience=5,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}\")\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "# Validation function\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    print(f\"Val Loss: {epoch_loss:.4f}, Val Accuracy: {epoch_accuracy:.4f}\")\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "# Main training loop\n",
        "num_epochs = 20\n",
        "print(f\"\\nStarting training for {num_epochs} epochs...\\n\")\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    train_loss, train_accuracy = train_epoch(model, train_dataloader, criterion, optimizer, device)\n",
        "    val_loss, val_accuracy = validate_epoch(model, val_dataloader, criterion, device)\n",
        "\n",
        "    # Log metrics to wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_accuracy,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_accuracy\": val_accuracy\n",
        "    })\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "print(\"\\nTraining finished.\")\n",
        "\n",
        "# Final test evaluation\n",
        "def evaluate_model(model, dataloader, criterion, device, set_name=\"Test Set\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / total_samples\n",
        "    accuracy = correct_predictions / total_samples\n",
        "\n",
        "    print(f\"\\n{set_name} Results:\")\n",
        "    print(f\"  Loss: {avg_loss:.4f}\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Log test metrics to wandb\n",
        "    wandb.log({\n",
        "        f\"{set_name.lower().replace(' ', '_')}_loss\": avg_loss,\n",
        "        f\"{set_name.lower().replace(' ', '_')}_accuracy\": accuracy\n",
        "    })\n",
        "\n",
        "# Evaluate on the test set\n",
        "evaluate_model(model, test_new_dataloader, criterion, device, set_name=\"New Test Set (from original train data)\")\n",
        "\n",
        "# Finish wandb run\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "An9am4MpIour",
        "outputId": "93329b80-58ed-44c7-bbc1-cd110967e15e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "Epoch 1/20\n",
            "Train Loss: 1.7616, Train Accuracy: 0.3077\n",
            "Val Loss: 1.5215, Val Accuracy: 0.4117\n",
            "Epoch 2/20\n",
            "Train Loss: 1.4679, Train Accuracy: 0.4351\n",
            "Val Loss: 1.3501, Val Accuracy: 0.4671\n",
            "Epoch 3/20\n",
            "Train Loss: 1.3543, Train Accuracy: 0.4801\n",
            "Val Loss: 1.2852, Val Accuracy: 0.5120\n",
            "Epoch 4/20\n",
            "Train Loss: 1.2744, Train Accuracy: 0.5136\n",
            "Val Loss: 1.2377, Val Accuracy: 0.5161\n",
            "Epoch 5/20\n",
            "Train Loss: 1.2217, Train Accuracy: 0.5391\n",
            "Val Loss: 1.2389, Val Accuracy: 0.5236\n",
            "Epoch 6/20\n",
            "Train Loss: 1.1594, Train Accuracy: 0.5582\n",
            "Val Loss: 1.1778, Val Accuracy: 0.5493\n",
            "Epoch 7/20\n",
            "Train Loss: 1.1159, Train Accuracy: 0.5709\n",
            "Val Loss: 1.1790, Val Accuracy: 0.5635\n",
            "Epoch 8/20\n",
            "Train Loss: 1.0514, Train Accuracy: 0.5997\n",
            "Val Loss: 1.1781, Val Accuracy: 0.5526\n",
            "Epoch 9/20\n",
            "Train Loss: 0.9913, Train Accuracy: 0.6231\n",
            "Val Loss: 1.1715, Val Accuracy: 0.5628\n",
            "Epoch 10/20\n",
            "Train Loss: 0.9335, Train Accuracy: 0.6391\n",
            "Val Loss: 1.1603, Val Accuracy: 0.5654\n",
            "Epoch 11/20\n",
            "Train Loss: 0.8691, Train Accuracy: 0.6621\n",
            "Val Loss: 1.1997, Val Accuracy: 0.5686\n",
            "Epoch 12/20\n",
            "Train Loss: 0.8092, Train Accuracy: 0.6918\n",
            "Val Loss: 1.2176, Val Accuracy: 0.5695\n",
            "Epoch 13/20\n",
            "Train Loss: 0.7468, Train Accuracy: 0.7125\n",
            "Val Loss: 1.2064, Val Accuracy: 0.5733\n",
            "Epoch 14/20\n",
            "Train Loss: 0.6814, Train Accuracy: 0.7390\n",
            "Val Loss: 1.2952, Val Accuracy: 0.5605\n",
            "Epoch 15/20\n",
            "Train Loss: 0.6310, Train Accuracy: 0.7589\n",
            "Val Loss: 1.3404, Val Accuracy: 0.5770\n",
            "Epoch 16/20\n",
            "Train Loss: 0.5699, Train Accuracy: 0.7817\n",
            "Val Loss: 1.3861, Val Accuracy: 0.5644\n",
            "Epoch 17/20\n",
            "Train Loss: 0.4219, Train Accuracy: 0.8412\n",
            "Val Loss: 1.4311, Val Accuracy: 0.5918\n",
            "Epoch 18/20\n",
            "Train Loss: 0.3772, Train Accuracy: 0.8585\n",
            "Val Loss: 1.4241, Val Accuracy: 0.5897\n",
            "Epoch 19/20\n",
            "Train Loss: 0.3529, Train Accuracy: 0.8687\n",
            "Val Loss: 1.4517, Val Accuracy: 0.5925\n",
            "Epoch 20/20\n",
            "Train Loss: 0.3356, Train Accuracy: 0.8759\n",
            "Val Loss: 1.4871, Val Accuracy: 0.5883\n",
            "\n",
            "Training finished.\n",
            "\n",
            "New Test Set (from original train data) Results:\n",
            "  Loss: 1.4583\n",
            "  Accuracy: 0.6007\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>new_test_set_(from_original_train_data)_accuracy</td><td>▁</td></tr><tr><td>new_test_set_(from_original_train_data)_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇████</td></tr><tr><td>train_loss</td><td>█▇▆▆▅▅▅▅▄▄▄▃▃▃▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▅▅▆▇▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▃▃▁▁▁▁▁▂▂▂▄▄▅▆▆▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>new_test_set_(from_original_train_data)_accuracy</td><td>0.60065</td></tr><tr><td>new_test_set_(from_original_train_data)_loss</td><td>1.45833</td></tr><tr><td>train_accuracy</td><td>0.87594</td></tr><tr><td>train_loss</td><td>0.33564</td></tr><tr><td>val_accuracy</td><td>0.58834</td></tr><tr><td>val_loss</td><td>1.48712</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">neat-snowflake-3</strong> at: <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/dvb3omyf' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/dvb3omyf</a><br> View project at: <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250531_140448-dvb3omyf/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, min_delta=0.0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.best_loss = float('inf')\n",
        "        self.counter = 0\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if val_loss < self.best_loss - self.min_delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True"
      ],
      "metadata": {
        "id": "1yBfe-F8CL7C"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "run = wandb.init(\n",
        "    project=\"Facial_Expression_Recognition_1\",\n",
        "    config={\n",
        "        \"architecture\": \"ImprovedCNN_Combined\",\n",
        "        \"num_classes\": 7,\n",
        "        \"dropout_prob\": 0.4,\n",
        "        \"learning_rate\": 0.0005,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"weight_decay\": 5e-3,\n",
        "        \"scheduler\": \"ReduceLROnPlateau\",\n",
        "        \"scheduler_patience\": 5,\n",
        "        \"scheduler_factor\": 0.1,\n",
        "        \"loss_function\": \"CrossEntropyLoss\",\n",
        "        \"batch_size\": 64,\n",
        "        \"epochs\": 20,\n",
        "        \"input_size\": (48, 48)\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "38r-drrGaR_s",
        "outputId": "04e90dd6-2f4d-43a0-ae9b-ea21b27263e6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250531_141016-hte7lcza</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/hte7lcza' target=\"_blank\">glad-dream-4</a></strong> to <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/hte7lcza' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/hte7lcza</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 7\n",
        "model = ImprovedCNN_Combined(num_classes=num_classes, dropout_prob=0.4)\n",
        "\n",
        "model.to(device)\n",
        "print(f\"Model moved to: {device}\")\n",
        "wandb.watch(model, log=\"all\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKe2KgYqJN1f",
        "outputId": "50630d5a-cb04-4626-dc2f-14831dc63542"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model moved to: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "import wandb\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"Facial_Expression_Recognition_1\", name=\"early stopping + modifications\")  # Change project and run names as needed\n",
        "\n",
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Learning rate and optimizer\n",
        "learning_rate = 0.0005\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-3)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.1,\n",
        "    patience=5,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Training function\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    print(f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.4f}\")\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "# Validation function\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    print(f\"Val Loss: {epoch_loss:.4f}, Val Accuracy: {epoch_accuracy:.4f}\")\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "# Main training loop\n",
        "num_epochs = 20\n",
        "print(f\"\\nStarting training for {num_epochs} epochs...\\n\")\n",
        "early_stopping = EarlyStopping(patience=5, min_delta=1e-3)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "    train_loss, train_accuracy = train_epoch(model, train_dataloader, criterion, optimizer, device)\n",
        "    val_loss, val_accuracy = validate_epoch(model, val_dataloader, criterion, device)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Log to wandb\n",
        "    wandb.log({\n",
        "        \"epoch\": epoch + 1,\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_accuracy\": train_accuracy,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"val_accuracy\": val_accuracy,\n",
        "        \"learning_rate\": optimizer.param_groups[0]['lr']\n",
        "    })\n",
        "\n",
        "    early_stopping(val_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "print(\"\\nTraining finished.\")\n",
        "\n",
        "# Final test evaluation\n",
        "def evaluate_model(model, dataloader, criterion, device, set_name=\"Test Set\"):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_samples += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / total_samples\n",
        "    accuracy = correct_predictions / total_samples\n",
        "\n",
        "    print(f\"\\n{set_name} Results:\")\n",
        "    print(f\"  Loss: {avg_loss:.4f}\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "    wandb.log({\n",
        "        f\"{set_name.lower().replace(' ', '_')}_loss\": avg_loss,\n",
        "        f\"{set_name.lower().replace(' ', '_')}_accuracy\": accuracy\n",
        "    })\n",
        "\n",
        "# Call test evaluation\n",
        "evaluate_model(model, test_new_dataloader, criterion, device, set_name=\"New Test Set (from original train data)\")\n",
        "\n",
        "# Finish wandb run\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JTRKbKS-C4tD",
        "outputId": "0cffcdf3-a5fe-4692-b4f1-29a596f18f0a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>learning_rate</td><td>▁▁</td></tr><tr><td>train_accuracy</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>val_accuracy</td><td>█▁</td></tr><tr><td>val_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>learning_rate</td><td>0.0005</td></tr><tr><td>train_accuracy</td><td>0.76546</td></tr><tr><td>train_loss</td><td>0.65009</td></tr><tr><td>val_accuracy</td><td>0.55398</td></tr><tr><td>val_loss</td><td>1.20521</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">early stopping + modifications</strong> at: <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/eh1jiiym' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/eh1jiiym</a><br> View project at: <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250531_142013-eh1jiiym/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250531_142034-n18vfz0c</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/n18vfz0c' target=\"_blank\">early stopping + modifications</a></strong> to <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/n18vfz0c' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/n18vfz0c</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "Epoch 1/20\n",
            "Train Loss: 1.6518, Train Accuracy: 0.3530\n",
            "Val Loss: 1.5237, Val Accuracy: 0.3938\n",
            "Epoch 2/20\n",
            "Train Loss: 1.4291, Train Accuracy: 0.4519\n",
            "Val Loss: 1.4024, Val Accuracy: 0.4360\n",
            "Epoch 3/20\n",
            "Train Loss: 1.3327, Train Accuracy: 0.4899\n",
            "Val Loss: 1.2654, Val Accuracy: 0.5140\n",
            "Epoch 4/20\n",
            "Train Loss: 1.2800, Train Accuracy: 0.5118\n",
            "Val Loss: 1.2506, Val Accuracy: 0.5236\n",
            "Epoch 5/20\n",
            "Train Loss: 1.2362, Train Accuracy: 0.5324\n",
            "Val Loss: 1.2519, Val Accuracy: 0.5326\n",
            "Epoch 6/20\n",
            "Train Loss: 1.1991, Train Accuracy: 0.5439\n",
            "Val Loss: 1.1802, Val Accuracy: 0.5454\n",
            "Epoch 7/20\n",
            "Train Loss: 1.1633, Train Accuracy: 0.5607\n",
            "Val Loss: 1.1911, Val Accuracy: 0.5375\n",
            "Epoch 8/20\n",
            "Train Loss: 1.1312, Train Accuracy: 0.5731\n",
            "Val Loss: 1.1560, Val Accuracy: 0.5589\n",
            "Epoch 9/20\n",
            "Train Loss: 1.1010, Train Accuracy: 0.5868\n",
            "Val Loss: 1.2145, Val Accuracy: 0.5410\n",
            "Epoch 10/20\n",
            "Train Loss: 1.0773, Train Accuracy: 0.5965\n",
            "Val Loss: 1.2003, Val Accuracy: 0.5373\n",
            "Epoch 11/20\n",
            "Train Loss: 1.0425, Train Accuracy: 0.6070\n",
            "Val Loss: 1.1213, Val Accuracy: 0.5700\n",
            "Epoch 12/20\n",
            "Train Loss: 1.0128, Train Accuracy: 0.6244\n",
            "Val Loss: 1.1997, Val Accuracy: 0.5403\n",
            "Epoch 13/20\n",
            "Train Loss: 0.9802, Train Accuracy: 0.6325\n",
            "Val Loss: 1.1481, Val Accuracy: 0.5586\n",
            "Epoch 14/20\n",
            "Train Loss: 0.9549, Train Accuracy: 0.6469\n",
            "Val Loss: 1.1533, Val Accuracy: 0.5605\n",
            "Epoch 15/20\n",
            "Train Loss: 0.9204, Train Accuracy: 0.6606\n",
            "Val Loss: 1.1862, Val Accuracy: 0.5514\n",
            "Epoch 16/20\n",
            "Train Loss: 0.8848, Train Accuracy: 0.6750\n",
            "Val Loss: 1.1764, Val Accuracy: 0.5540\n",
            "Early stopping triggered.\n",
            "\n",
            "Training finished.\n",
            "\n",
            "New Test Set (from original train data) Results:\n",
            "  Loss: 1.1970\n",
            "  Accuracy: 0.5510\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>new_test_set_(from_original_train_data)_accuracy</td><td>▁</td></tr><tr><td>new_test_set_(from_original_train_data)_loss</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁▃▄▄▅▅▆▆▆▆▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▄▄▃▃▃▂▂▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▆▆▇▇▇█▇▇█▇██▇▇</td></tr><tr><td>val_loss</td><td>█▆▄▃▃▂▂▂▃▂▁▂▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>learning_rate</td><td>0.0005</td></tr><tr><td>new_test_set_(from_original_train_data)_accuracy</td><td>0.55096</td></tr><tr><td>new_test_set_(from_original_train_data)_loss</td><td>1.19699</td></tr><tr><td>train_accuracy</td><td>0.67504</td></tr><tr><td>train_loss</td><td>0.88475</td></tr><tr><td>val_accuracy</td><td>0.55398</td></tr><tr><td>val_loss</td><td>1.17641</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">early stopping + modifications</strong> at: <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/n18vfz0c' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1/runs/n18vfz0c</a><br> View project at: <a href='https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1' target=\"_blank\">https://wandb.ai/tvani22-free-university-of-tbilisi/Facial_Expression_Recognition_1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250531_142034-n18vfz0c/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}